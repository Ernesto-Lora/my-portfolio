<%- include("partials/header.ejs", { articleStyles: true }) %>


<div id="container">

  <h1> Fintech Weather Impact on Loan Delays</h1>
  <h3>Summary</h3>
  <p> At a fintech, I automated the ingestion of weather data via AWS Lambda, streamlined historical processing with Spark on EMR, and integrated everything into Redshift. The resulting QuickSight dashboards revealed that rain increased repayment delays by 20%, directly informing our revised risk models and credit strategies.</p>



<section id="business-challenge">
  <h3>Business Challenge</h3>
  <p>A fintech suspected that adverse weather events were driving seasonal spikes in loan repayment delays. Manual weather-data collection via CSV downloads was inefficient and error-prone, impeding timely risk assessment.</p>
</section>

<section id="objectives">
  <h3>Objectives</h3>
  <ul>
    <li>Automate daily ingestion of critical weather metrics (temperature, rainfall, humidity).</li>
    <li>Centralize weather and loan repayment data in a scalable data warehouse.</li>
    <li>Quantify weather‚Äôs impact on repayment delays to refine risk models.</li>
    <li>Deliver interactive dashboards for dynamic insights by region and season.</li>
  </ul>
</section>

<section id="technical-architecture">
  <h3>Technical Architecture &amp; Data Pipeline</h3>
  <p>The following diagram illustrates the end-to-end pipeline, from data ingestion to visualization:</p>
  <!-- Insert processing architecture diagram here -->
  <figure>
    <img src="images/fintech_ingestion/project2.png" alt="Data Processing Architecture" />
    <figcaption>Figure: AWS-based data pipeline for weather and loan data integration.</figcaption>
  </figure>

  <h4>Ingestion</h4>
  <p>An AWS Lambda function fetches daily weather data via API, with CloudWatch monitoring and alerting for failures.</p>

  <h4>Storage &amp; Processing</h4>
  <ul>
    <li><strong>Recent Data:</strong> Streamed into Amazon Redshift alongside loan repayment records.</li>
    <li><strong>Historical Data:</strong> Processed with Apache Spark on AWS EMR (or AWS Glue) and queried via Redshift Spectrum.</li>
  </ul>

  <h4>Analytics &amp; Visualization</h4>
  <p>Amazon QuickSight dashboards provide interactive views of correlation analyses, with filters for time range, region, and weather severity.</p>
</section>

<section id="data-schemas">
  <h3>Data Schemas</h3>
  <h4>Weather Data Table</h4>
  <table>
    <thead>
      <tr><th>Column</th><th>Type</th><th>Description</th></tr>
    </thead>
    <tbody>
      <tr><td>date</td><td>DATE</td><td>Observation date</td></tr>
      <tr><td>region_code</td><td>VARCHAR</td><td>Rural area identifier</td></tr>
      <tr><td>temperature</td><td>FLOAT</td><td>Daily average (¬∞F/¬∞C)</td></tr>
      <tr><td>rainfall</td><td>FLOAT</td><td>Total precipitation (mm/inches)</td></tr>
      <tr><td>humidity</td><td>FLOAT</td><td>Average daily humidity (%)</td></tr>
      <tr><td>weather_event</td><td>VARCHAR</td><td>Notable condition (e.g., "storm")</td></tr>
    </tbody>
  </table>

  <h4>Loan Repayment Data Table</h4>
  <table>
    <thead>
      <tr><th>Column</th><th>Type</th><th>Description</th></tr>
    </thead>
    <tbody>
      <tr><td>loan_id</td><td>VARCHAR</td><td>Loan identifier</td></tr>
      <tr><td>customer_id</td><td>VARCHAR</td><td>Borrower identifier</td></tr>
      <tr><td>loan_amount</td><td>DECIMAL</td><td>Financed amount</td></tr>
      <tr><td>repayment_due_date</td><td>DATE</td><td>Scheduled date</td></tr>
      <tr><td>actual_repayment_date</td><td>DATE</td><td>Completed date</td></tr>
      <tr><td>delay_days</td><td>INTEGER</td><td>Days past due</td></tr>
      <tr><td>region_code</td><td>VARCHAR</td><td>Matches weather table</td></tr>
    </tbody>
  </table>
</section>

<section id="challenges-and-considerations">
  <h3>Implementation Challenges</h3>
  <ul>
    <li><strong>Data Integration:</strong> Aligning disparate timestamps and region codes, handling missing values and unit conversions.</li>
    <li><strong>Scalability:</strong> Optimizing Spark/Glue jobs and Redshift Spectrum queries for multi-year datasets.</li>
    <li><strong>Reliability:</strong> Building robust Lambda functions to manage API rate limits and outages.</li>
    <li><strong>Analytical Accuracy:</strong> Ensuring statistical significance in correlation analysis and accounting for confounders.</li>
  </ul>
</section>

<section id="business-impact">
  <h3>Business Impact</h3>
  <p>The automated pipeline enabled AgriLoan Capital to identify that monsoon-season rainfall correlated with a 20% increase in repayment delays. This insight refined underwriting models and informed proactive borrower communications, enhancing risk management and positioning the firm as a climate-aware fintech leader.</p>
</section>


  <p>Thanks for reading! üßë‚Äçüíªüíï</p>
</div>

</html>
